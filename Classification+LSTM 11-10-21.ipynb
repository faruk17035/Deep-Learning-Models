{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification+LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbbmPW4Cr33M6K9hssPzOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faruk17035/Deep-Learning-Models/blob/main/Classification%2BLSTM%2011-10-21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfPAxYmRI8Q9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPYbabCtKAgm",
        "outputId": "2b794c80-e40d-4884-e1cd-64f196b3f8a2"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ-8_rljKD9P",
        "outputId": "20245949-ce66-46ba-8617-0d162818a8c3"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_excel\n",
        "file = '/content/gdrive/MyDrive/Glove3decimal.csv' \n",
        "#df = pd.read_csv(file)\n",
        "tweet = pd.read_csv(file)\n",
        "print(tweet)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       tpc0   tpc1   tpc2   tpc3   tpc4  ...  tpc508  tpc509  tpc510  tpc511  Target\n",
            "0     0.000 -0.026  0.057  0.045  0.080  ...   0.039  -0.051   0.123  -0.076       0\n",
            "1    -0.052  0.003  0.055  0.073  0.071  ...   0.022  -0.056   0.113  -0.035       1\n",
            "2    -0.037 -0.040  0.074  0.029  0.067  ...   0.054  -0.056   0.150  -0.063       0\n",
            "3    -0.007 -0.032  0.035  0.056  0.087  ...   0.028  -0.069   0.123  -0.058       0\n",
            "4     0.035 -0.039  0.076  0.013  0.086  ...   0.079  -0.051   0.137  -0.084       1\n",
            "...     ...    ...    ...    ...    ...  ...     ...     ...     ...     ...     ...\n",
            "2099 -0.024 -0.039  0.045  0.050  0.088  ...   0.045  -0.048   0.133  -0.077       1\n",
            "2100 -0.040 -0.016  0.046  0.063  0.076  ...   0.003  -0.050   0.129  -0.050       1\n",
            "2101 -0.021 -0.021  0.060  0.042  0.067  ...   0.038  -0.061   0.119  -0.055       1\n",
            "2102 -0.012 -0.020  0.055  0.040  0.078  ...   0.041  -0.063   0.153  -0.069       1\n",
            "2103 -0.048 -0.025  0.039  0.047  0.085  ...   0.034  -0.051   0.125  -0.066       1\n",
            "\n",
            "[2104 rows x 513 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DvtCcwsLLQv"
      },
      "source": [
        "features = np.array(df.columns[:-1])\n",
        "target = 'Target'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 20)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woMbHmk1LiSt",
        "outputId": "17230b20-7d69-4fca-a7ea-e0b8be07e572"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1683, 512), (421, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lFxAJ5ZNwjP"
      },
      "source": [
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import (LSTM, \n",
        "                          Embedding, \n",
        "                          BatchNormalization,\n",
        "                          Dense, \n",
        "                          TimeDistributed, \n",
        "                          Dropout, \n",
        "                          Bidirectional,\n",
        "                          Flatten, \n",
        "                          GlobalMaxPool1D)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MruvoSzfLn2V",
        "outputId": "939c6367-3358-4ea5-c83e-373774edbacc"
      },
      "source": [
        "## Not run\n",
        "#Checking the class distribution\n",
        "x = tweet.Target.value_counts()\n",
        "sns.barplot(x.index, x, palette='cool')\n",
        "plt.gca().set_ylabel('tweets')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'tweets')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzSshER6QrWi"
      },
      "source": [
        "length_long_sentence = 512"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edSXtf3VOiVb"
      },
      "source": [
        "def BLSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=X_train.shape[0], \n",
        "                        output_dim=X_train.shape[1], \n",
        "                        weights = [X_train], \n",
        "                        input_length=length_long_sentence))\n",
        "    model.add(Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.2)))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGpAXMGTOuDM",
        "outputId": "2aeeec76-1ca7-4039-eec9-eb9a6f1cf68e"
      },
      "source": [
        "model = BLSTM()\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor = 'val_loss', \n",
        "    verbose = 1, \n",
        "    save_best_only = True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor = 'val_loss', \n",
        "    factor = 0.2, \n",
        "    verbose = 1, \n",
        "    patience = 5,                        \n",
        "    min_lr = 0.001\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    epochs = 7,\n",
        "    batch_size = 32,\n",
        "    validation_data = [X_test, y_test],\n",
        "    verbose = 1,\n",
        "    callbacks = [reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/7\n",
            "53/53 [==============================] - 307s 6s/step - loss: 0.7250 - accuracy: 0.5122 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to model.h5\n",
            "Epoch 2/7\n",
            "53/53 [==============================] - 301s 6s/step - loss: 0.7334 - accuracy: 0.4955 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "Epoch 3/7\n",
            "53/53 [==============================] - 292s 6s/step - loss: 0.7241 - accuracy: 0.4819 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "Epoch 4/7\n",
            "53/53 [==============================] - 294s 6s/step - loss: 0.7119 - accuracy: 0.5134 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "Epoch 5/7\n",
            "53/53 [==============================] - 291s 6s/step - loss: 0.7154 - accuracy: 0.4920 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "Epoch 6/7\n",
            "53/53 [==============================] - 296s 6s/step - loss: 0.6981 - accuracy: 0.5169 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "Epoch 7/7\n",
            "53/53 [==============================] - 297s 6s/step - loss: 0.7097 - accuracy: 0.4926 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw4akhScQiC-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}